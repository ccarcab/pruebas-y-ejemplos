<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title type="html">Narayana Community Priorities</title><link rel="alternate" href="https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html" /><author><name>Michael Musgrove</name></author><id>https://jbossts.blogspot.com/2022/03/narayana-community-priorities.html</id><updated>2022-03-04T13:24:00Z</updated><content type="html">NARAYANA COMMUNITY PRIORITIES The following is an outline of our near term priorities for the Narayana open source transaction manager. They have been set based on input from the community, including the narayana-users . It is not necessarily a complete list, so please continue to share your own thoughts on whether you agree they are the right focus for the project, in some respects the list is quite ambitious and we encourage/need and welcome continued contributions and discussion from the community to help achieve these goals. COMMUNITY ENGAGEMENT 1. Improve inclusiveness by building a community of users: * produce clear guidance on how to contribute with different levels of guidance * responsive to the community (PRs, queries, issues, rooms etc) * issue labels for new contributors and for tasks that we need help with * make sure all new features are publicised (blog, articles, docs, etc) * regular blog posts with runnable and focused examples * acknowledge contributors in release announcements * encourage discussions in the community (i.e. minimise private team discussions) JAVA VERSIONS 1. : this work is already well under way. Java SE 11 is now the minimum runtime supported by WildFly and Jakarta EE compatible implementations. 2. (i.e. SE 11 will the minimum supported version) and add INTEGRATING CONTEMPORARY SERVICES: 1. 2. . This task depends on CLOUD STRATEGY: 1. 2. An improved cloud strategy for JTA around recovery (again we have already started work in this area). Currently we need to create a bespoke solution for every cloud, e.g. the . This task includes provision of a more “cloud ready” transaction log store. The task still needs to be pinned down but some relevant input material includes: 1. (this includes an investigation of whether an Infinispan based store is feasible - note that earlier versions were incompatible with our needs) 2. 3. 4. 5. There is also the forum item: which will help with using Narayana in cloud deployments: * the task should also explore the pros and cons of storing it for crash recovery purposes * the forum thread also includes some work that we may do on validating our current uid solution for cloud environments 3. Better integration of LRA in cloud environments: 1. 2. TRANSACTION LOG STORES 1. Persistent Memory: narayana already provides a pmem based object store which we would like to 2. 3. to our own Object Store locking (FileLock.java) for managing concurrent access to a transaction log. It should be configurable at runtime or build time (Quarkus is a good use case). If the runtime platform does not provide the capability then a default fallback mechanism will be defined. UPGRADES/DEPRECATION/REMOVAL/REPLACEMENT OF EXISTING FUNCTIONALITY: 1. Remove in favour of using . We are tracking this work using . 2. Remove - it was previously deprecated by the . The issue tracker is 3. 4. Upgrade to JUnit 5 (from 4) for unit testing: OTHER 1. Improved support for asynchronous APIs. Although we continue to be tied to XA and very few resource managers support the asynchronous component of the , there are still things we would like to do in this area including</content><dc:creator>Michael Musgrove</dc:creator></entry><entry><title type="html">WildFly on the Cloud with Helm</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/openshift/wildfly-on-the-cloud-with-helm/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/openshift/wildfly-on-the-cloud-with-helm/</id><updated>2022-03-04T10:58:22Z</updated><content type="html">Helm is a package Manager that simplify the management of manifest resources you need for Kubernetes projects. In this article we will walk through an example WildFly application which we will deploy on OpenShift using Helm Charts Helm overview and setup Helm charts can simplify the complexities of dependency management for a Kubernetes project. With ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>Data conversion in Pandas dataframes: 3 approaches to try</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/04/data-conversion-pandas-dataframes-3-approaches-try" /><author><name>adkulkarni</name></author><id>7d4d9045-c1e4-4e80-be88-366d3762e9fc</id><updated>2022-03-04T07:00:00Z</updated><published>2022-03-04T07:00:00Z</published><summary type="html">&lt;p&gt;I have been working on data analysis for almost three years, and there are some starters that I think are essential for every data analyst using the popular &lt;a href="https://pandas.pydata.org"&gt;Pandas&lt;/a&gt; library for &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt;. If you often do data transformations in Pandas, you know how annoying it can be to search the web for basic information every time you get started with a new dataframe.&lt;/p&gt; &lt;p&gt;For me, one of those sore points is encoding text data. For some reason, I can never remember a good way to encode data when I need it. So, I decided to note down my three favorite ways of doing so. Let me know in the comments if you have any other alternatives.&lt;/p&gt; &lt;h2&gt;1. Using the replace method with a dictionary&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;replace&lt;/code&gt; method is great for manipulating column data in a Pandas dataframe. You can define a dictionary as an input argument for this method when converting a column of text data to integers. Let's take the simple dataframe called &lt;code&gt;data&lt;/code&gt; with two columns, one text and one Boolean:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="500"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;shouldihaveanothercoffee&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;always&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;sure&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;False&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;definitely&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;True&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;You can convert the &lt;code&gt;shouldihaveanothercoffee&lt;/code&gt; column to a numerical column using the replace method as follows:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["shouldihaveanothercoffee"].replace({"always":0, "sure":1, "definitely":2}, inplace=True)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;shouldihaveanothercoffee&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;2. Using the astype method&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;astype&lt;/code&gt; method can convert data from one type to another. Boolean values to integers. Here, I'll show how you can use the method to convert a Boolean column &lt;code&gt;isitfridayyet&lt;/code&gt; in the previously shown dataframe to Integer values (&lt;code&gt;True&lt;/code&gt; being treated as &lt;code&gt;1&lt;/code&gt; and &lt;code&gt;False&lt;/code&gt; as &lt;code&gt;0&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["isitfridayyet"] = data["isitfridayyet"].astype(int)&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;3. Using the apply method&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;apply&lt;/code&gt; method is another convenient method to handle data modifications for a data frame. You can use this method with explicit type conversion and the lambda function to convert data from Boolean to integer:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;data["isitfridayyet"] = data["isitfridayyet"].apply(lambda x: int(x)) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following table shows the output from that statement:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="401"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th class="text-align-center" scope="col"&gt;Index&lt;/th&gt; &lt;th class="text-align-center" scope="col"&gt;isitfridayyet&lt;/th&gt; &lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td class="text-align-center"&gt;&lt;code&gt;2&lt;/code&gt;&lt;/td&gt; &lt;td class="text-align-center"&gt;&lt;code&gt;1&lt;/code&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;I hope these suggestions help you with your next Pandas project. Feel free to leave comments or questions on this article to discuss the methods or tell me what other methods I missed.&lt;/p&gt; &lt;p&gt;Useful documentation on the methods I've discussed can be found here:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html"&gt;pandas.DataFrame.replace&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html"&gt;pandas.DataFrame.astype&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"&gt;pandas.DataFrame.apply&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/04/data-conversion-pandas-dataframes-3-approaches-try" title="Data conversion in Pandas dataframes: 3 approaches to try"&gt;Data conversion in Pandas dataframes: 3 approaches to try&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>adkulkarni</dc:creator><dc:date>2022-03-04T07:00:00Z</dc:date></entry><entry><title type="html">Editing Serverless Workflow definitions with our new VSCode extension</title><link rel="alternate" href="https://blog.kie.org/2022/03/editing-serverless-workflow-definitions-with-our-new-vscode-extension.html" /><author><name>Paulo Martins</name></author><id>https://blog.kie.org/2022/03/editing-serverless-workflow-definitions-with-our-new-vscode-extension.html</id><updated>2022-03-03T21:32:40Z</updated><content type="html">We are happy to announce the first release of our , which allows users to have a side-by-side real-time preview of their workflows while editing JSON and YAML files inside VSCode (*.sw.json, *.sw.yaml, *.sw.yml). This extension complies with the CNCF specification v0.8. FEATURES INCLUDED In this first release we are delivering the following features: REAL-TIME DIAGRAM PREVIEW RENDERING The diagram on the right side of the editor is updated on each change made, providing the user quick feedback on their modifications. If the workflow is invalid, the preview will have some transparency and be frozen since the last valid state. AUTOMATIC SVG GENERATION By default, the extension saves an SVG file in the same directory as the workflow file. If you want to change that, you can check the extension configuration options, where you will be able to deactivate it or customize the file name and directory where the file is saved. AUTO-COMPLETE SUGGESTIONS In this version, the editor provides basic auto-complete suggestions based on the specification and the expressions used in the current file. NEXT STEPS For the next releases, we are already working on several new features that will improve what the user can do inside the editor: SERVICE CATALOG Users will be able to register Open API endpoints in their environment, allowing the editor to provide augmentation options to make it easy to add new functions to the workflow. AUTO-COMPLETE SUGGESTIONS ENHANCEMENT Besides showing suggestions based on the specification and the current file expressions, the user will also be able to add functions and its parameters quickly by selecting suggestions linked to their service catalog. VALIDATION Inline detailed validation and integration with the VSCode’s Validation UI, which will provide a detailed list of errors and warnings of the workflow. -------------------------------------------------------------------------------- That is all for now, the extension is already available at the . And stay tuned for our next releases! The post appeared first on .</content><dc:creator>Paulo Martins</dc:creator></entry><entry><title type="html">Prototypes and Live Queries: A Sneak Peek Into The Future of Drools (featuring Debezium and Apache Calcite)</title><link rel="alternate" href="https://blog.kie.org/2022/03/prototypes-and-live-queries-a-sneak-peek-into-the-future-of-drools-featuring-debezium-and-apache-calcite.html" /><author><name>Mario Fusco</name></author><id>https://blog.kie.org/2022/03/prototypes-and-live-queries-a-sneak-peek-into-the-future-of-drools-featuring-debezium-and-apache-calcite.html</id><updated>2022-03-03T11:31:41Z</updated><content type="html">Drools is a hybrid rule engine, allowing both data-driven forward chaining (rules match facts in the working memory producing other facts that in turn activate other rules) and goal-driven backward chaining (queries match facts in the working memory, eventually invoking other queries to retrieve them). This second usage pattern is also available in streaming mode through which allow attaching a listener for change events instead of returning an iterable result set. This feature allows to create incremental materialized views of the facts inserted in the working memory and then it makes Drools a good fit to analyze and aggregate live streams of data. For instance this could be applied to the stream of changes generated by a change data capture tool like .  Moreover it would be nice to have the possibility of querying Drools not only in DRL, but also using a more standard and well known query language like SQL. This is possible by using a tool to parse and analyze SQL query like and translating the results of this analysis into a Drools query. I put these ideas together in a to demonstrate how this could work. In particular in I’m simulating the output stream produced by Debezium in json format by incrementally inserting into my query engine messages like the following {    "before":null,    "after":{       "id":1001,       "first_name":"Sally",       "last_name":"Thomas",       "email":"sally.thomas@acme.com"    },    "source":{       "version":"1.8.0.Alpha2",       "connector":"postgresql",      "name":"dbserver1",       "snapshot":"true",       "db":"postgres",       "schema":"inventory",       "table":"customers",    },    "op":"r",    "ts_ms":1643708392757,    "transaction":null } What Debezium does is setting the before field of this json to null and populate the after if a new record has been inserted, doing the opposite if it has been deleted and populating both fields if it has been updated, so I’m inserting, removing or updating facts into the Drools session .  Note that the facts inserted in the engine cannot be plain pojos since there doesn’t exist any Java class modeling them. For this reason they are modeled with structural typing as s, a into Drools. Here the types of the different facts ingested by the rule engine is no longer determined by their Java classes, but simply by a logical name that in this case coincides with the name of the table of the record to be processed. As anticipated my other goal was having the possibility to query this system with like the following SELECT * FROM customers c LEFT JOIN addresses a on c.id = a.customer_id To achieve this, in a first iteration, I used Calcite to simply parse the SQL query and visit the resulting AST to defined through the . Then I realized that Calcite can do much more than simply parsing the SQL query: it also analyzes the query, producing the corresponding . This analysis provides a normalized and optimized view of the SQL query, so I wrote a of my transformer from SQL to Drools queries that is feeded by the relational algebra produced by Calcite.  with the generated by Debezium that I used in my test and that simply outputs the incremental matches to the transformed SQL query found by Drools, produces an output like the following rowInserted:    customers: {last_name=Thomas, id=1001, first_name=Sally, email=sally.thomas@acme.com};    addresses: {city=Hamburg, street=42 Main Street, id=100001, customer_id=1001} --- 0 rowInserted:    customers: {last_name=Thomas, id=1001, first_name=Sally, email=sally.thomas@acme.com};    addresses: {city=Berlin, street=11 Post Dr., id=100002, customer_id=1001} --- 1 rowInserted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Los Angeles, street=12 Rodeo Dr., id=100003, customer_id=1002} --- 2 rowInserted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Monterey, street=1 Debezium Plaza, id=100004, customer_id=1002} --- 3 rowInserted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Monterey, street=2 Debezium Plaza, id=100005, customer_id=1002} rowUpdated:    customers: {last_name=Thomas, id=1001, first_name=Sarah, email=sally.thomas@acme.com};    addresses: {city=Berlin, street=11 Post Dr., id=100002, customer_id=1001} rowUpdated:    customers: {last_name=Thomas, id=1001, first_name=Sarah, email=sally.thomas@acme.com};    addresses: {city=Hamburg, street=42 Main Street, id=100001, customer_id=1001} --- 4 rowDeleted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Los Angeles, street=12 Rodeo Dr., id=100003, customer_id=1002} rowDeleted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Monterey, street=2 Debezium Plaza, id=100005, customer_id=1002} rowDeleted:    customers: {last_name=Bailey, id=1002, first_name=George, email=gbailey@foobar.com};    addresses: {city=Monterey, street=1 Debezium Plaza, id=100004, customer_id=1002} --- 5 In a similar way the test provides also a second use case, this time , demonstrating how this implementation also works with it. In my opinion this proof of concept demonstrates the flexibility of Drools and its ability to efficiently process and aggregate data. The recent introduction of prototypes extends these capabilities even in cases when these data are structured but untyped as discussed in this article. The post appeared first on .</content><dc:creator>Mario Fusco</dc:creator></entry><entry><title>REST API error modeling with Quarkus 2.0</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20" /><author><name>Stephen Nimmo</name></author><id>9833bd66-12c9-4dad-ac2c-390cc83dd6e1</id><updated>2022-03-03T07:00:00Z</updated><published>2022-03-03T07:00:00Z</published><summary type="html">&lt;p&gt;In the &lt;a href="https://developers.redhat.com/articles/2022/01/01/quarkus-ground-customer-api-revisited"&gt;previous installment of the Quarkus from the ground up series&lt;/a&gt;, you saw the beginnings of a fully functional, &lt;a href="https://www.openapis.org/"&gt;OpenAPI-compliant&lt;/a&gt; REST &lt;a href="https://developers.redhat.com/topics/api-management/"&gt;API&lt;/a&gt; built using &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. That article covered all of the architectural layers, from managing database schemas with &lt;a href="https://flywaydb.org/"&gt;Flyway&lt;/a&gt; to building the API itself with &lt;a href="https://quarkus.io/guides/resteasy-reactive"&gt;RESTEasy Reactive&lt;/a&gt;. You saw happy-path use cases, but didn't get into the concepts around error handling. In this article, you'll dive into error handling, build a solid error response model, and see how you can help API consumers reduce toil in their work.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Once you're ready to dive in, you can &lt;a href="https://github.com/quarkus-ground-up/customer-api/tree/0.0.2"&gt;download the complete source code for this article&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Why error handling matters&lt;/h2&gt; &lt;p&gt;Error handling is one of those aspects of a system's architecture that deserves more attention. When you're designing a new feature, most of the discussion centers on what happens when things go right—but when that feature goes into production, most of the attention is focused on what is going wrong. As is true with observability and other architectural concerns, if the development team spent a bit more time upfront in the design of error handling within an application, they could reap considerable rewards in production in terms of application availability and stability.&lt;/p&gt; &lt;h2&gt;Out-of-the-box functionality&lt;/h2&gt; &lt;p&gt;Before modeling and implementing error handling into the sample application, it would be good to explore what error responses look like without any additional code. Begin by &lt;a href="https://github.com/quarkus-ground-up/customer-api"&gt;cloning the repository&lt;/a&gt; for the application you developed in the last article. Next, you'll need to create a new test that uses &lt;a href="https://site.mockito.org/"&gt;Mockito&lt;/a&gt; to create a response with an unexpected runtime exception. To use Mockito, you need to add the Quarkus extension:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; &lt;dependency&gt; &lt;groupId&gt;io.quarkus&lt;/groupId&gt; &lt;artifactId&gt;quarkus-junit5-mockito&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The test creates a mocked &lt;code&gt;CustomerService&lt;/code&gt; instance configured to throw a &lt;code&gt;RuntimeException&lt;/code&gt;. When the response is returned, extract it as a &lt;code&gt;Response&lt;/code&gt; object and set a breakpoint to better understand what the returned JSON structure looks like:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import com.redhat.customer.CustomerService; import io.quarkus.test.junit.QuarkusTest; import io.quarkus.test.junit.mockito.InjectMock; import io.restassured.response.Response; import org.junit.jupiter.api.Test; import org.mockito.Mockito; import static io.restassured.RestAssured.given; @QuarkusTest public class ThrowableMapperTest { @InjectMock CustomerService customerService; @Test public void throwUnexpectedRuntimeExceptionInCustomerService() { Mockito.when(customerService.findAll()).thenThrow(new RuntimeException("Completely Unexpected")); Response errorResponse = given() .when() .get("/customers") .then() .statusCode(500) .extract().response(); errorResponse.prettyPrint(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here's the response JSON structure:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "details": "Error id 327095e1-b8fa-491e-b3f1-e8944bd8023c-1, java.lang.RuntimeException: Completely Unexpected", "stack": "java.lang.RuntimeException: Completely Unexpected\n\tat com.redhat.customer.CustomerService_ClientProxy.findAll(Unknown Source)\n\tat com.redhat.customer.CustomerResource.get(CustomerResource.java:43)\n\tat com.redhat.customer.CustomerResource$quarkusrestinvoker$get_458c9ef52b4c83180ab57cf43ffebc046fc42b84.invoke(Unknown Source)\n\tat org.jboss.resteasy.reactive.server.handlers.InvocationHandler.handle(InvocationHandler.java:29)\n\tat org.jboss.resteasy.reactive.server.handlers.InvocationHandler.handle(InvocationHandler.java:7)\n\tat org.jboss.resteasy.reactive.common.core.AbstractResteasyReactiveContext.run(AbstractResteasyReactiveContext.java:141)\n\tat io.quarkus.vertx.core.runtime.VertxCoreRecorder$13.runWith(VertxCoreRecorder.java:543)\n\tat org.jboss.threads.EnhancedQueueExecutor$Task.run(EnhancedQueueExecutor.java:2449)\n\tat org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1478)\n\tat org.jboss.threads.DelegatingRunnable.run(DelegatingRunnable.java:29)\n\tat org.jboss.threads.ThreadLocalResettingRunnable.run(ThreadLocalResettingRunnable.java:29)\n\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n\tat java.base/java.lang.Thread.run(Thread.java:833)" } &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;This response is pretty gnarly, and the API consumer would have to perform a ton of parsing to get useful information out of it. The &lt;code&gt;stack&lt;/code&gt; field also leaks information about our implementation, which is a security problem. While the framework has transformed a &lt;code&gt;RuntimeException&lt;/code&gt; into a well-formed HTTP response with the proper HTTP status code, the result is unusable.&lt;/p&gt; &lt;h3&gt;Out of the box: ConstraintViolationException&lt;/h3&gt; &lt;p&gt;Now that you've seen the results of an unexpected exception, let's take a look at the constraint violation use case. This application uses the &lt;a href="https://hibernate.org/validator/"&gt;Hibernate Validator&lt;/a&gt; framework to validate data objects as they are passed between layers. The &lt;code&gt;Customer&lt;/code&gt; object has &lt;code&gt;@NotEmpty&lt;/code&gt; validations on both the &lt;code&gt;firstName&lt;/code&gt; and &lt;code&gt;lastName&lt;/code&gt; fields, along with an &lt;code&gt;@Email&lt;/code&gt; validator on the &lt;code&gt;email&lt;/code&gt; field that will validate the value of the &lt;code&gt;String&lt;/code&gt; as a well-formed email address if present. When the method parameter for the &lt;code&gt;Customer&lt;/code&gt; object has a &lt;code&gt;@Valid&lt;/code&gt; annotation, the validator framework will perform the validations. If any constraint violations are present, the framework will throw the &lt;code&gt;ConstraintViolationException&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To see what happens out of the box, you can temporarily create a new test based on one of the existing tests. This temporary test will send a &lt;code&gt;Customer&lt;/code&gt; object with a null &lt;code&gt;firstName&lt;/code&gt; field:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; @Test public void postFailNoFirstNameResponse() { Customer customer = createCustomer(); customer.setFirstName(null); Response errorResponse = given() .contentType(ContentType.JSON) .body(customer) .post() .then() .statusCode(400) .extract().response(); errorResponse.prettyPrint(); } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here's the JSON response:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "title": "Constraint Violation", "status": 400, "violations": [ { "field": "post.customer.firstName", "message": "must not be empty" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;While it's a vast improvement over the unexpected runtime exception case, the structure and content are still insufficient. The response structure is too specific to the underlying implementation. You want a more generic design that can handle all error responses.&lt;/p&gt; &lt;h2&gt;Update the validation messages&lt;/h2&gt; &lt;p&gt;Building a better error response model begins with the error messages. How you implement those messages will depend on your need for internationalization. If your API is scoped for use in a single language, the annotations themselves can use &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-message-interpolation"&gt;default message interpolation&lt;/a&gt; by passing a message parameter to the annotation. This method supports building messages using &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-interpolation-with-message-expressions"&gt;message expressions&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt; @NotEmpty(message = "Customer's first name is required.") private String firstName; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If your application needs to support internationalization, you should use message properties files. Name these files using the pattern &lt;code&gt;ValidationMessages_loc.properties&lt;/code&gt;, substituting the appropriate locale abbreviation (&lt;code&gt;en&lt;/code&gt;, &lt;code&gt;es&lt;/code&gt;, etc.) for &lt;code&gt;loc&lt;/code&gt;, so developers can build &lt;a href="https://docs.jboss.org/hibernate/stable/validator/reference/en-US/html_single/#section-resource-bundle-locator"&gt;message bundles&lt;/a&gt; for every language. Here's an example of the &lt;code&gt;ValidationMessages.properties&lt;/code&gt; file, the default, non-locale-specific message bundle placed in the &lt;code&gt;src/main/resources&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; System.error=An unexpected error has occurred. Please contact support. Customer.firstName.required=Customer's first name is required Customer.lastName.required=Customer's last name is required Customer.email.invalid=Customer's email address is invalid &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With this method, you can use the keys of the message bundle to express the correct validation message as part of the annotation:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; @NotEmpty(message = "{Customer.firstName.required}") private String firstName; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you've implemented this response model, your response JSON content will contain much more helpful error messages:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; { "title": "Constraint Violation", "status": 400, "violations": [ { "field": "post.customer.firstName", "message": "Customer's first name is required" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now that you have taken care of the error message aspect of the application, you can restructure the error response.&lt;/p&gt; &lt;h2&gt;Model the error response&lt;/h2&gt; &lt;p&gt;Modeling the error response can be a point of contention in application architecture because no full-featured standards govern the response structure. There have been some attempts at standardization, such as a Request for Comments (RFC) published in 2016 called &lt;a href="https://datatracker.ietf.org/doc/html/rfc7807"&gt;Problem details for HTTP APIs&lt;/a&gt;. This RFC is a good start for standardizing things like the field names of the response structure. However, the design doesn't easily support common use cases like the constraint violation, so the result is a collection of errors for a single response.&lt;/p&gt; &lt;p&gt;When it comes to modeling errors, developers must choose between multiple structures or a single unified structure. Using multiple structures requires the consumer to perform introspection on the error structure to determine where the data resides. In contrast, a single suitable structure requires the consumer to create an implied model where the cardinality of the messages is the focal point. Here's are a couple of examples of how an error structure response might be modeled:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; // System Error Response - Single { "errorId": "971e0747-f7ec-4d21-915b-c66257db05c3", "message": "An unexpected error has occurred. Please contact support" } // System Error Response - Multiple { "errorId": "971e0747-f7ec-4d21-915b-c66257db05c3", "errors": [ { "message": "An unexpected error has occurred. Please contact support" } ] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For this article, we will focus on creating a single unified error response structure. This structure should handle both application and system errors, whether they are expected or not:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import com.fasterxml.jackson.annotation.JsonInclude; import lombok.EqualsAndHashCode; import lombok.Getter; import java.util.List; @Getter @EqualsAndHashCode public class ErrorResponse { @JsonInclude(JsonInclude.Include.NON_NULL) private String errorId; private List&lt;ErrorMessage&gt; errors; public ErrorResponse(String errorId, ErrorMessage errorMessage) { this.errorId = errorId; this.errors = List.of(errorMessage); } public ErrorResponse(ErrorMessage errorMessage) { this(null, errorMessage); } public ErrorResponse(List&lt;ErrorMessage&gt; errors) { this.errorId = null; this.errors = errors; } public ErrorResponse() { } @Getter @EqualsAndHashCode public static class ErrorMessage { @JsonInclude(JsonInclude.Include.NON_NULL) private String path; private String message; public ErrorMessage(String path, String message) { this.path = path; this.message = message; } public ErrorMessage(String message) { this.path = null; this.message = message; } public ErrorMessage() { } } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Some implementation notes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The application uses &lt;a href="https://projectlombok.org/"&gt;Lombok&lt;/a&gt; to manage the boilerplate code, as in the previous article in this series. &lt;ul&gt;&lt;li&gt;The &lt;code&gt;@Getter&lt;/code&gt; annotation creates getters for the class variables and the &lt;code&gt;@EqualsAndHashCode&lt;/code&gt; annotation autogenerates the &lt;code&gt;equals&lt;/code&gt; and &lt;code&gt;hashCode&lt;/code&gt; methods using a default methodology in which all class variables are used for both implementations.&lt;/li&gt; &lt;li&gt;As mentioned in the last article, you should use libraries such as Lombok with extreme care. These annotations can sometimes create generated implementations with easily hidden performance or runtime execution impacts.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;The &lt;code&gt;@JsonInclude(JsonInclude.Include.NON_NULL)&lt;/code&gt; &lt;a href="https://fasterxml.github.io/jackson-annotations/javadoc/2.9/com/fasterxml/jackson/annotation/JsonInclude.html"&gt;annotation&lt;/a&gt; provides instructions to not serialize the item if it is null.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Catching Throwable: Introduction to the ExceptionMapper&lt;/h2&gt; &lt;p&gt;Now that you have the data structure for the error response, you can begin to model how to handle exceptions in the application. In Quarkus, you can use the &lt;a href="https://jakarta.ee/specifications/platform/9/apidocs/jakarta/ws/rs/ext/exceptionmapper"&gt;JAX-RS ExceptionMapper&lt;/a&gt; class to perform the necessary transformations between exceptions and your error response.&lt;/p&gt; &lt;p&gt;The exception mapper infrastructure starts by catching &lt;a href="https://cr.openjdk.java.net/~iris/se/11/latestSpec/api/java.base/java/lang/Throwable.html"&gt;Throwable&lt;/a&gt;, which is the ultimate superclass of all errors and exceptions, checked and unchecked. By catching &lt;code&gt;Throwable&lt;/code&gt; in an &lt;code&gt;ExceptionMapper&lt;/code&gt;, you can ensure that all unexpected exceptions can be caught, processed, logged, and transformed to the &lt;code&gt;ErrorResponse&lt;/code&gt;. This will eliminate the unwanted behavior in which an unexpected exception might leak stack traces and other internals back to the consumer.&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import lombok.extern.slf4j.Slf4j; import javax.ws.rs.core.Response; import javax.ws.rs.ext.ExceptionMapper; import javax.ws.rs.ext.Provider; import java.util.ResourceBundle; import java.util.UUID; @Provider @Slf4j public class ThrowableMapper implements ExceptionMapper&lt;Throwable&gt; { @Override public Response toResponse(Throwable e) { String errorId = UUID.randomUUID().toString(); log.error("errorId[{}]", errorId, e); String defaultErrorMessage = ResourceBundle.getBundle("ValidationMessages").getString("System.error"); ErrorResponse.ErrorMessage errorMessage = new ErrorResponse.ErrorMessage(defaultErrorMessage); ErrorResponse errorResponse = new ErrorResponse(errorId, errorMessage); return Response.status(Response.Status.INTERNAL_SERVER_ERROR).entity(errorResponse).build(); } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Some implementation notes:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The implementation uses the &lt;a href="https://projectlombok.org/features/log"&gt;Lombok &lt;code&gt;@Slf4j&lt;/code&gt;&lt;/a&gt; annotation to create a private, final, and static reference to a log variable that uses the Simple Logging Facade for Java (&lt;a href="https://www.slf4j.org/"&gt;SLF4J&lt;/a&gt;).&lt;/li&gt; &lt;li&gt;&lt;code&gt;ResourceBundle.getBundle("ValidationMessages")&lt;/code&gt; allows you to get a specific error message from the configured validation messages. You'll learn more about the details of this when you dive into the constraint violation exception scenario in the next section.&lt;/li&gt; &lt;li&gt;In the &lt;code&gt;toResponse&lt;/code&gt; method, a unique identifier for the error is created using &lt;a href="https://docs.oracle.com/javase/8/docs/api/java/util/UUID.html"&gt;UUID&lt;/a&gt;. This identifier is used when generating the log statements to facilitate debugging in a production environment. If you pass the unique identifier back to the consumer, the consumer can then reference the identifier in a support ticket, which the support team can use to quickly search the logs and identify what the cause of the error might be.&lt;/li&gt; &lt;li&gt;Once the error is logged, it is then transformed into the &lt;code&gt;ErrorResponse&lt;/code&gt; object and returned to the consumer with an HTTP status code of 500, denoting a generic internal server error.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;ConstraintViolationExceptionMapper&lt;/h2&gt; &lt;p&gt;Now, consider the constraint violation use case once again. What you would like to see is a response message body produced with an array of error messages. To model this, you can use the existing &lt;code&gt;ErrorResponse&lt;/code&gt; and write a new &lt;code&gt;ConstraintViolationExceptionMapper&lt;/code&gt; to handle the specific exception:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; package com.redhat.exception; import javax.validation.ConstraintViolationException; import javax.ws.rs.core.Response; import javax.ws.rs.ext.ExceptionMapper; import javax.ws.rs.ext.Provider; import java.util.List; import java.util.stream.Collectors; @Provider public class ConstraintViolationExceptionMapper implements ExceptionMapper&lt;ConstraintViolationException&gt; { @Override public Response toResponse(ConstraintViolationException e) { List&lt;ErrorResponse.ErrorMessage&gt; errorMessages = e.getConstraintViolations().stream() .map(constraintViolation -&gt; new ErrorResponse.ErrorMessage(constraintViolation.getPropertyPath().toString(), constraintViolation.getMessage())) .collect(Collectors.toList()); return Response.status(Response.Status.BAD_REQUEST).entity(new ErrorResponse(errorMessages)).build(); } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;With both of these mechanisms in place, the error response body is exactly what you're looking for:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;{ "errors": [ { "path": "post.customer.lastName", "message": "Customer's last name is required" }, { "path": "post.customer.email", "message": "Customer's email address is invalid" }, { "path": "post.customer.firstName", "message": "Customer's first name is required" } ] }&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Why your enterprise should standardize its error model&lt;/h2&gt; &lt;p&gt;Using the common &lt;code&gt;ErrorResponse&lt;/code&gt; object and creating &lt;code&gt;ExceptionMapper&lt;/code&gt; implementations for all of your use cases gives you a unified and easily consumable API error model. This approach works great for an individual team; however, another problem arises when all of the development teams in an enterprise design their error models independently and end up with different naming conventions and structures, especially in a polyglot world. The API consumers, whether they are other &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservices&lt;/a&gt; or front-end developers building UIs, end up toiling over the myriad of different error responses.&lt;/p&gt; &lt;p&gt;This is a great opportunity for enterprise standardization. Bringing together the API teams in a common &lt;a href="https://www.atlassian.com/agile/agile-at-scale/spotify"&gt;guild&lt;/a&gt; allows everyone in the company to come together in building and publishing a common standard for error responses. This eliminates toil on the API consumer end and reduces API development work by utilizing existing, documented response structures and even building shared libraries for use across teams.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/03/rest-api-error-modeling-quarkus-20" title="REST API error modeling with Quarkus 2.0"&gt;REST API error modeling with Quarkus 2.0&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Stephen Nimmo</dc:creator><dc:date>2022-03-03T07:00:00Z</dc:date></entry><entry><title>Introduction to the Node.js reference architecture, Part 7: Code coverage</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage" /><author><name>Lucas Holmquist</name></author><id>6a3f46c3-86a3-484e-8052-10e2e69868ef</id><updated>2022-03-02T07:00:00Z</updated><published>2022-03-02T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, we'll look at why testing in &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; applications is important. You'll also learn how to measure code coverage, how to maximize your investment in testing, and what the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Node.js reference architecture&lt;/a&gt; recommends to ensure adequate code coverage. &lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Read the other articles in our Node.js reference architecture series so far&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Overview of the Node.js reference architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developer.ibm.com/languages/node-js/blogs/nodejs-reference-architectire-pino-for-logging/"&gt;Logging in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/05/17/introduction-nodejs-reference-architecture-part-3-code-consistency"&gt;Code consistency in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 4: &lt;a href="https://developers.redhat.com/articles/2021/06/22/introduction-nodejs-reference-architecture-part-4-graphql-nodejs"&gt;GraphQL in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 5: &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 6: &lt;a href="https://developers.redhat.com/articles/2021/12/03/introduction-nodejs-reference-architecture-part-6-choosing-web-frameworks"&gt;Choosing web frameworks&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Part 7: Code coverage&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What is code coverage?&lt;/h2&gt; &lt;p&gt;Code coverage is a software testing metric that determines how much code in a project has been successfully validated under a test procedure, which in turn, helps in analyzing how thoroughly software has been verified.&lt;/p&gt; &lt;p&gt;To measure the lines of code that are actually exercised by test runs, the code coverage metric takes various criteria into consideration. The following are a few important coverage criteria.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Function coverage:&lt;/strong&gt; The functions in the source code that are called and executed at least once.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Statement coverage:&lt;/strong&gt; The number of statements that have been successfully validated in the source code.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Path coverage: &lt;/strong&gt;The flows containing a sequence of controls and conditions that have worked well at least once.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Branch or decision coverage:&lt;/strong&gt; The decision control structures (loops, for example) that have executed properly.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Condition coverage:&lt;/strong&gt; The Boolean expressions that are validated and that execute both &lt;code&gt;TRUE&lt;/code&gt; and &lt;code&gt;FALSE&lt;/code&gt; during the test runs.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;What modules should you use for code coverage?&lt;/h2&gt; &lt;p&gt;If you've read the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;previous installments in the Node.js reference architecture series&lt;/a&gt;, you know that we recommend modules that our teams are familiar with and use regularly. This article is no different. The teams defining the reference architecture have decided on two modules that we recommend for code coverage:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.npmjs.com/package/nyc"&gt;nyc&lt;/a&gt;, probably the most popular tool for code coverage. One of the main reasons this module is the most popular is that it works well with most JavaScript testing frameworks. &lt;code&gt;nyc&lt;/code&gt; is the successor command-line interface (CLI) for &lt;code&gt;istanbul&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.npmjs.com/package/jest"&gt;Jest&lt;/a&gt;, which generates coverage when you run the tool with the &lt;code&gt;--coverage&lt;/code&gt; option.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This article's examples use &lt;code&gt;nyc&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Testing example&lt;/h2&gt; &lt;p&gt;Download the example from the &lt;a href="https://github.com/nodeshift-blog-examples/ref-arch-code-coverage"&gt;Nodeshift example repository&lt;/a&gt;. The example is made up of two simple functions located in the &lt;code&gt;index.js&lt;/code&gt; file, and a test in the &lt;code&gt;test&lt;/code&gt; directory that uses the &lt;a href="https://mochajs.org/"&gt;Mocha test runner&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The first function adds two numbers:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;function addTwoNumbers(x, y) { return x + y; }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This function can be easily covered by this simple test:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-javascript"&gt;describe('testing for coverage', () =&gt; { it ('should add 2 numbers correctly', () =&gt; { assert.equal(addTwoNumbers(1,1), 2); }); });&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Code coverage can be generated easily too: Just call the &lt;code&gt;nyc&lt;/code&gt; module in conjunction with our test to generate the coverage report.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;package.json&lt;/code&gt; might look something like this to run our tests while generating coverage reports:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;"scripts": { "test": "mocha", "coverage": "nyc npm run test" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Executing&lt;code&gt; npm run coverage&lt;/code&gt; is all that is needed. Because we wrote only one test, our statement coverage will be only about 18%. To increase code coverage, we have to test the other functions  and statements:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt; testing for coverage ✔ should add 2 numbers correctly 1 passing (3ms) ----------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------|---------|----------|---------|---------|------------------- All files | 18.18 | 0 | 50 | 18.18 | index.js | 18.18 | 0 | 50 | 18.18 | 9-23 ----------|---------|----------|---------|---------|------------------- &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once the other tests are written and run, code coverage should be at 100%:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;testing for coverage ✔ should add 2 numbers correctly ✔ should test that phish is the best band ✔ should test the beatles are a good band too ✔ should test that nickelback is not that good ✔ should test that all other bands are pretty good 5 passing (6ms) ----------|---------|----------|---------|---------|------------------- File | % Stmts | % Branch | % Funcs | % Lines | Uncovered Line #s ----------|---------|----------|---------|---------|------------------- All files | 100 | 100 | 100 | 100 | index.js | 100 | 100 | 100 | 100 | ----------|---------|----------|---------|---------|-------------------&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;What to cover&lt;/h2&gt; &lt;p&gt;After much discussion, the reference architecture team's guidance on what to cover is broken down into two sections:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Coverage for modules:&lt;/strong&gt; It is important to cover all public APIs. Basically, any exposed API that a user can interact with should be covered.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Coverage for applications:&lt;/strong&gt; This coverage should be driven by the key user stories and key paths that the application can take. Unlike a module, here it is much more important to test and cover paths that are critical for your application than to worry about covering all paths.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Acceptable coverage thresholds&lt;/h2&gt; &lt;p&gt;We realized in our discussions that not all projects are created equal. Some projects might be starting from scratch, whereas others contain legacy code bases.&lt;/p&gt; &lt;p&gt;For new projects without legacy code, a good percentage threshold is about 70%. This is because, with new projects, it is relatively easy to add tests while creating the application or module.&lt;/p&gt; &lt;p&gt;It might be a little harder to add coverage to a project that is older and doesn't have any coverage yet, because adding tests to old code with technical debt can be a challenge, especially for someone new coming into the project. In this case, a good percentage threshold is about 30%.&lt;/p&gt; &lt;p&gt;It is also our experience that when adding coverage to an older code base, focusing on the key user stories gives you the best return on your investment. Focusing on the path and branch/decision coverage can also maximize the investment required to get to 30%.&lt;/p&gt; &lt;h2&gt;Guidance for open source projects&lt;/h2&gt; &lt;p&gt;For free and &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; projects, it might be helpful to post the results of the coverage to an external service, such as &lt;a href="https://coveralls.io/"&gt;Coveralls&lt;/a&gt;. Creating issues that suggest ways to increase code coverage could be a way to attract contributors to the project.&lt;/p&gt; &lt;p&gt;It is also common to report the coverage increase or decrease percentage during a pull request or merge request CI run. In our experience, it is best to use this information in a code review rather than by blocking a merge.&lt;/p&gt; &lt;h2&gt;What's next?&lt;/h2&gt; &lt;p&gt;We cover new topics regularly as part of the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Node.js reference architecture series&lt;/a&gt;. While you wait for the next installment, we invite you to visit the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub, where you'll see the work we've already done and the kinds of topics you can look forward to in the future.&lt;/p&gt; &lt;p&gt;To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage" title="Introduction to the Node.js reference architecture, Part 7: Code coverage"&gt;Introduction to the Node.js reference architecture, Part 7: Code coverage&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Lucas Holmquist</dc:creator><dc:date>2022-03-02T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.7.3.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-7-3-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-7-3-final-released/</id><updated>2022-03-02T00:00:00Z</updated><content type="html">Today, we released a new maintenance release for our 2.7 release train: 2.7.3.Final. Thanks to all the people reporting issues, providing reproducers, fixes… , it’s really appreciated. It is a safe upgrade for anyone already using 2.7. If you are not using 2.7 already, please refer to the 2.7 migration guide....</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title>Package and run your Java Maven application on OpenShift in seconds</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/03/01/package-and-run-your-java-maven-application-openshift-seconds" /><author><name>Rohan Kumar</name></author><id>e18fd085-843d-4bd5-89c3-6dd8f7dc7206</id><updated>2022-03-01T07:00:00Z</updated><published>2022-03-01T07:00:00Z</published><summary type="html">&lt;p&gt;Making a &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; out of an application, and moving it into &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, can be a complicated task involving many tools and edits. &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; makes it much easier. This article offers an exercise with a &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; application that you can run on the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;. In this exercise you will:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Generate a simple Java application from the &lt;a href="https://code.quarkus.io/"&gt;Quarkus bootstrapping site&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Provision a cost-free development cluster in OpenShift.&lt;/li&gt; &lt;li&gt;Add the &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin"&gt;Eclipse JKube OpenShift Maven plugin&lt;/a&gt; to your project.&lt;/li&gt; &lt;li&gt;Deploy the Java application to Red Hat OpenShift.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;Besides &lt;a href="https://developers.redhat.com/developer-sandbox/get-started"&gt;opening a cost-free account on the Developer Sandbox&lt;/a&gt;, you need the following tools to do this activity:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The &lt;a href="https://developers.redhat.com/blog/2021/04/21/access-your-developer-sandbox-for-red-hat-openshift-from-the-command-line#first_stop__the_openshift_dashboard"&gt;OpenShift command-line interface (CLI)&lt;/a&gt;, which offers the &lt;code&gt;oc&lt;/code&gt; command.&lt;/li&gt; &lt;li&gt;A &lt;a href="https://adoptopenjdk.net/"&gt;Java Development Kit&lt;/a&gt; (JDK).&lt;/li&gt; &lt;li&gt;A text editor.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Generate a simple Java application&lt;/h2&gt; &lt;p&gt;Once you have access to a cluster on Red Hat OpenShift, you need to prepare a Java Maven project. For this exercise, you will create a sample application on your local system before deploying the application to OpenShift. There are various alternatives for creating a container-ready Java application, including &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot,&lt;/a&gt; Micronaut, or &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. We'll pick Quarkus because it has been trending for the past few years.&lt;/p&gt; &lt;p&gt;So go to the &lt;a href="https://code.quarkus.io/"&gt;Quarkus bootstrapping site&lt;/a&gt; and generate a project from there. Choose Maven as a build tool and check the boxes for the RESTEasy JAX-RS and RESTEasy JSON-B dependencies, which add starter code for a sample REST endpoint (Figure 1). Click the blue &lt;strong&gt;Generate your application &lt;/strong&gt;button to download the files.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/depend.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/depend.png?itok=IaHCtoEB" width="1345" height="758" alt="Generate a Quarkus application from the Quarkus starter website, choosing the RESTEasy JAX-RS and RESTEasy JSON-B dependencies." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. Generate a Quarkus application from the Quarkus starter website, choosing the RESTEasy JAX-RS and RESTEasy JSON-B dependencies. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Let's add a simple random generator endpoint that prints a random JSON message at an endpoint named &lt;code&gt;/random&lt;/code&gt;. I've provided the &lt;a href="https://github.com/rohankanojia-forks/quarkus-random-generator"&gt;source code for the application in my GitHub repository&lt;/a&gt;. Download this repository, move to a directory on your computer where you'd like to store the code, and install it as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ unzip quarkus-random-generator.zip &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Go to the project directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cd quarkus-random-generator/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Open this project in a text editor or IDE of your choice. The source code of the random generator application consists of the following three files:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;RandomResponse&lt;/code&gt;: A plain old Java object that serves as a model for the response&lt;/li&gt; &lt;li&gt;&lt;code&gt;RandomGeneratorService&lt;/code&gt;: A utility class that generates the random response&lt;/li&gt; &lt;li&gt;&lt;code&gt;RandomGeneratorResource:&lt;/code&gt;: The class where you declare your REST endpoint and call &lt;code&gt;RandomGeneratorService&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;You can place the files in a single package or in different packages. In my case, the directory structure looks like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;quarkus-random-generator : $ tree src/main/java/ src/main/java/ └── com └── redhat └── developers └── demos └── quarkus ├── model │ └── RandomResponse.java ├── rest │ └── RandomGeneratorResource.java └── service └── RandomGeneratorService.java 8 directories, 3 files &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The contents of &lt;code&gt;RandomResponse.java&lt;/code&gt; are:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.redhat.developers.demos.quarkus.model; public class RandomResponse { private String id; public RandomResponse(String id) { this.id = id; } public String getId() { return id; } public void setId(String id) { this.id = id; } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The contents of &lt;code&gt;RandomGeneratorService.java&lt;/code&gt; are:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.redhat.developers.demos.quarkus.service; import com.redhat.developers.demos.quarkus.model.RandomResponse; import java.util.UUID; public class RandomGeneratorService { private static final UUID id = UUID.randomUUID(); public RandomResponse createRandomMessage() { return new RandomResponse(id.toString()); } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The contents of &lt;code&gt;RandomGeneratorResource.java&lt;/code&gt; are:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-java"&gt;package com.redhat.developers.demos.quarkus.rest; import com.redhat.developers.demos.quarkus.service.RandomGeneratorService; import javax.ws.rs.GET; import javax.ws.rs.Path; import javax.ws.rs.Produces; import javax.ws.rs.core.MediaType; import javax.ws.rs.core.Response; @Path("/random") public class RandomGeneratorResource { @GET @Produces(MediaType.APPLICATION_JSON) public Response hello() { RandomGeneratorService randomGeneratorService = new RandomGeneratorService(); return Response.ok(randomGeneratorService.createRandomMessage()).build(); } } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you've added these files to your project, build it using the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw clean install&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If the build is successful, run the project by executing a runnable JAR generated by Quarkus:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ java -jar target/quarkus-app/quarkus-run.jar&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Open the &lt;code&gt;localhost:8080/random&lt;/code&gt; link in your browser, you should see something like Figure 2.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/local.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/local.png?itok=lnKAymTW" width="578" height="268" alt="When you open the localhost:8080/random link, you can see data as JSON or Raw Data, and view headers." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. When you open the localhost:8080/random link, you can see data as JSON or Raw Data, and view headers. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Cool, your application seems to be working locally. Next, we'll deploy the application to the Developer Sandbox for Red Hat OpenShift.&lt;/p&gt; &lt;h2&gt;Provision your sandbox&lt;/h2&gt; &lt;p&gt;The Developer Sandbox for Red Hat OpenShift is a free OpenShift cluster that gives you the experience of working with a Kubernetes cluster and learning more about Kubernetes. Unlike other cloud platforms, Developer Sandbox doesn't require a credit card. You just need to create a &lt;a href="https://sso.redhat.com/auth/realms/redhat-external/login-actions/registration?client_id=rhd-web&amp;tab_id=lsjXrypZMMk"&gt;Red Hat account&lt;/a&gt; and use that to provision your OpenShift cluster.&lt;/p&gt; &lt;p&gt;Once you've created an account and logged into your OpenShift cluster, you should get a console screen like Figure 3.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/dash.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/dash.png?itok=r1TPy7a1" width="1440" height="569" alt="When you first log into the console for the Developer Sandbox, you get a dashboard with no resources." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: When you first log into the console for the Developer Sandbox, you get a dashboard with no resources. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;You can specify Developer Sandbox parameters by using the console. You can also deploy applications, check their status, and do many other tasks there. But for some tasks, you need the &lt;code&gt;oc&lt;/code&gt; command-line tool. After you install it on your machine, you can use it to connect to your OpenShift cluster from your terminal.&lt;/p&gt; &lt;p&gt;Get the login command you need by pulling down the menu that bears your user name in the upper right corner of your console screen. Choose the &lt;strong&gt;Copy login command&lt;/strong&gt; menu item (Figure 4). You should be taken to a screen that says &lt;strong&gt;Display token&lt;/strong&gt;. Clock that link to see the token as well as a complete &lt;code&gt;oc login&lt;/code&gt; command, which you should copy.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/login_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/login_0.png?itok=M-tyxW_t" width="407" height="233" alt="Pull down the menu on the top left side for your user name and choose the "Copy login command" menu item." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Pull down the menu on the top left side for your user name and choose the "Copy login command" menu item. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Paste the command into your terminal:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc login --token=sha256~%TOKEN% --server=https://%SERVER%:6443 Logged into "https://%SERVER%:6443" as "%USERNAME%" using the token provided. You have access to the following projects and can switch between them with 'oc project &lt;projectname&gt;': * %USERNAME%-dev %USERNAME%-stage Using project "%USERNAME-dev". Welcome! See 'oc help' to get started. &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can learn more about the &lt;code&gt;oc&lt;/code&gt; command in the article &lt;a href="https://developers.redhat.com/blog/2021/04/21/access-your-developer-sandbox-for-red-hat-openshift-from-the-command-line#"&gt;Access your Developer Sandbox for Red Hat OpenShift from the command line&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add the OpenShift Maven plugin to your project&lt;/h2&gt; &lt;p&gt;You'll be using the &lt;a href="https://github.com/eclipse/jkube"&gt;Eclipse JKube&lt;/a&gt; plugin to package and deploy this application to Red Hat OpenShift. Since you're using Maven for this exercise, download the latest version of the &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin"&gt;OpenShift Maven plugin&lt;/a&gt; from &lt;a href="https://search.maven.org/search?q=g:%22org.eclipse.jkube%22%20AND%20a:%22openshift-maven-plugin%22"&gt;Maven Central&lt;/a&gt;. If you're a Gradle user, you will also find the &lt;a href="https://www.eclipse.org/jkube/docs/openshift-gradle-plugin"&gt;OpenShift Gradle plugin&lt;/a&gt; useful for your projects. You can find more information about Eclipse JKube in the following articles:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/24/java-development-on-top-of-kubernetes-using-eclipse-jkube"&gt;Java development on top of Kubernetes using Eclipse JKube&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/01/28/introduction-to-eclipse-jkube-java-tooling-for-kubernetes-and-red-hat-openshift?source=sso"&gt;Introduction to Eclipse JKube: Java tooling for Kubernetes and Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2021/12/09/get-started-gradle-plugins-eclipse-jkube"&gt;Get started with Eclipse JKube Kubernetes/OpenShift Gradle Plugins&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;You can add the plugin to the &lt;code&gt;build&lt;/code&gt; section of your &lt;code&gt;pom.xml&lt;/code&gt;.It is advisable to keep the plugin in a separate OpenShift profile, in the &lt;code&gt;profiles&lt;/code&gt; section:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;profile&gt; &lt;id&gt;openshift&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;openshift-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${openshift-maven-plugin.version}&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Deploy the application to OpenShift&lt;/h2&gt; &lt;p&gt;Once you've added the Maven plugin to the project, use it to build a container image, generate YAML manifests, and apply them to the OpenShift cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:build oc:resource oc:apply -Popenshift&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The following OpenShift Maven plugin goals carry out the tasks we need for this exercise:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#jkube:build"&gt;oc:build&lt;/a&gt;: Creates a container image for your Java Maven application using the &lt;a href="https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#source-build"&gt;Source to Image (S2I)&lt;/a&gt; build strategy. The image is built in a pod and pushed to OpenShift's internal container registry.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#jkube:resource"&gt;oc:resource&lt;/a&gt;: Generates opinionated YAML manifests (DeploymentConfig, Service, Route, etc.) for your Java Maven application. You can view the manifests in the &lt;code&gt;target/classes/META-INF/jkube/openshift&lt;/code&gt; directory.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#jkube:apply"&gt;oc:apply&lt;/a&gt;: Applies these generated YAML manifests to the connected OpenShift Cluster. You can think of this as the equivalent of an &lt;code&gt;oc apply&lt;/code&gt; or &lt;code&gt;kubectl apply&lt;/code&gt; command.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Earlier in this article, you logged into your OpenShift cluster using the &lt;code&gt;oc login&lt;/code&gt; command, automatically setting up several properties. But if you want to deploy an application without having logged into the cluster previously, you need to set the pr properties shown in Table 1.&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="803"&gt;&lt;caption&gt;Table 1. OpenShift cluster configuration properties required for a deployment without a login.&lt;/caption&gt; &lt;tbody&gt;&lt;tr&gt;&lt;th&gt;Property&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubernetes.master&lt;/code&gt;&lt;/td&gt; &lt;td&gt;URL of the OpenShift cluster&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubernetes.auth.token&lt;/code&gt;&lt;/td&gt; &lt;td&gt;OpenShift API token received from the &lt;strong&gt;Copy login command&lt;/strong&gt; console menu item&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubernetes.namespace&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Namespace where you want to deploy the application&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubernetes.auth.tryServiceAccount&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Whether to check for a mounted service account&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;kubernetes.auth.tryKubeConfig&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Whether to check for the &lt;code&gt;KubeConfig&lt;/code&gt; file&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Once the application is deployed, you can check whether its pods got created in the Developer Sandbox web console. In the &lt;strong&gt;Administrator&lt;/strong&gt; view, go to &lt;strong&gt;Workloads→Pods&lt;/strong&gt;. There you should see something like Figure 5.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/pods.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/pods.png?itok=wnjgOHt0" width="1440" height="363" alt="The Pods view in the console shows the status of each pod in the cluster." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The Pods view in the console shows the status of each pod in the cluster. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Once your application pods are in the &lt;strong&gt;Running&lt;/strong&gt; state, you can access your application using the route URL from the OpenShift web console. In the &lt;strong&gt;Administrator&lt;/strong&gt; view, go to &lt;strong&gt;Networking→Routes&lt;/strong&gt;. You should see something like Figure 6.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/routes.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/routes.png?itok=47Wg5fHU" width="1440" height="462" alt="The Routes view in the console shows the location of each route and lets you connect to it." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: The Routes view in the console shows the location of each route and lets you connect to it. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;You can copy the URL from the console and paste it into a browser's location bar to view the application. Figure 7 shows the running application, which looks the same as Figure 2 but is now running in your OpenShift cluster instead of your local system.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/open.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/open.png?itok=Ychyp25P" width="991" height="249" alt="The application running in your OpenShift cluster shows the same interface as the local application shown in Figure 2." loading="lazy" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7. The application running in your OpenShift cluster shows the same interface as the local application shown in Figure 2. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;And that's it—you've successfully deployed a Java Maven application to a Red Hat OpenShift Cluster.&lt;/p&gt; &lt;p&gt;Once you've done testing your application, you can undeploy it using the &lt;code&gt;undeploy&lt;/code&gt; goal in the OpenShift Maven plugin:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:undeploy -Popenshift &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this activity, you've learned how easy it is to deploy a Java application to Red Hat OpenShift using Eclipse JKube's OpenShift Maven plugin. You don't need to worry about building a Dockerfile, doing an OpenShift build, maintaining YAML manifests, etc.—you can just focus on your application logic. To learn more about Eclipse JKube, check these links:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://www.eclipse.org/jkube/docs/"&gt;Eclipse's JKube documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/eclipse/jkube/issues"&gt;GitHub issue tracker&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/jkube"&gt;StackOverflow&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCpU2tjgpfkTVgeDq-DBSV7A"&gt;YouTube channel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://twitter.com/jkubeio"&gt;Twitter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://katacoda.com/jkubeio"&gt;Katakoda&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gitter.im/eclipse/jkube"&gt;Gitter chat&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/03/01/package-and-run-your-java-maven-application-openshift-seconds" title="Package and run your Java Maven application on OpenShift in seconds"&gt;Package and run your Java Maven application on OpenShift in seconds&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Rohan Kumar</dc:creator><dc:date>2022-03-01T07:00:00Z</dc:date></entry><entry><title type="html">6 things you can do with JBang but you can’t with Shell</title><link rel="alternate" href="http://www.mastertheboss.com/java/jbang-vs-jshell/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/jbang-vs-jshell/</id><updated>2022-02-28T13:33:54Z</updated><content type="html">Using Java as scripting language has become a popular option in the last few years thanks to the JShell tool. In this article we will learn how the JBang scripting tool can take your Java scripting power at another level. Automatic fetching of dependencies The most impressing feature of JBang is dependency management. You can ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
